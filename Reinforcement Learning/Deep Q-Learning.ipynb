{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v0').unwrapped\n",
    "# set up matplotlib\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "plt.ion()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 193\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "for i_episode in range(num_episodes):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the target network)\n",
    "        print('here',len(memory))\n",
    "        break\n",
    "        optimize_model()\n",
    "        \n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            plot_durations()\n",
    "            break\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "# env.close()\n",
    "# plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions = memory.sample(BATCH_SIZE)\n",
    "batch = Transition(*zip(*transitions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "non_final_mask.shape\n",
    "\n",
    "state_batch = torch.cat(batch.state)\n",
    "action_batch = torch.cat(batch.action)\n",
    "reward_batch = torch.cat(batch.reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [0],\n",
       "        [0],\n",
       "        [1],\n",
       "        [0],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1],\n",
       "        [1]], device='cuda:0')"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_batch.shape\n",
    "action_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 2]) torch.Size([128, 1])\n",
      "tensor([[-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011],\n",
      "        [-0.0242, -0.0011]], device='cuda:0', grad_fn=<AddmmBackward>) tensor([[-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0242],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011],\n",
      "        [-0.0011]], device='cuda:0', grad_fn=<GatherBackward>)\n"
     ]
    }
   ],
   "source": [
    "test=policy_net(state_batch)\n",
    "print(test.shape,test.gather(1, action_batch).shape)\n",
    "print(test,test.gather(1, action_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0242, device='cuda:0', grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()\n",
    "last_screen = get_screen()\n",
    "current_screen = get_screen()\n",
    "state = current_screen - last_screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADECAYAAACGNXroAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAQcElEQVR4nO3dfbAddX3H8ffHBBCQh4BggaBRi4h0FDUFrNYioqa2CjO1FdpacGypLR2lpSriTKutM5WpD3TGjhVFpWp9wgeQjg8YoWqrPAShghEDihIJRASKqHVEv/1jf6mHy725x+TmnPsL79fMztn97d7d79ndfM6e3zl7kqpCktSfB0y7AEnSljHAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBr4pKclOQL065jMUmyIkklWTrtWtQPA3w7k+TGJD9KcvfI8OZp1zVtSY5Ksn4brv/VSd6zrdYvzcZX++3Tc6rqM9MuojdJllbVPdOuY1vYnp/b/ZlX4PcjSd6S5LyR6TOTrM5gWZILk3w3yR1tfPnIspckeW2S/2pX9R9PsneS9ya5K8nlSVaMLF9JXpLkG0luS/KPSWY935I8OslFSW5Pcl2S39vMc9gjyTlJNiT5TqtpyTzPb1fgE8D+I+9K9m9XzecleU+Su4CTkhye5ItJ7mzbeHOSHUfWeehIrbcmOSPJKuAM4Plt3VePUeuSJK9v++YbwG/Nc+xe0dbx/baPnj6ynjOS3NDmrUly4MgxOCXJOmDdfPs6yU6tpm+35/YvSXZu845Ksj7JaUk2tuf0ws3VrAmoKoftaABuBI6ZY94uwNeBk4BfB24Dlrd5ewO/05bZDfgQ8LGRv70EuB54JLAH8NW2rmMY3sn9K/DOkeULuBjYC3hoW/aP27yTgC+08V2Bm4AXtvU8odV16BzP4WPAW9vf7QtcBvzpGM/vKGD9jHW9GvgJcBzDxczOwBOBI1stK4C1wKlt+d2ADcBpwAPb9BEj63rPL1Dri4GvAQe2fXRx22dLZ3nOB7d9tH+bXgE8so2/DPhKWybA44C9R47BRW39O8+3r4GzgAva8rsBHwf+YWT/3QP8HbAD8Gzgh8CyaZ/z9+dh6gU4LPABHQL8buDOkeFPRuYfDtwOfAs4YTPrOQy4Y2T6EuBVI9NvAD4xMv0c4KqR6QJWjUz/ObC6jZ/EzwP8+cDnZ2z7rcDfzlLTQ4AfAzuPtJ0AXDzf82PuAP/cPPvzVOCjI9v68hzLvZqRAJ+vVuCzwItH5j2TuQP8l4GNDC+WO8yYdx1w7Bw1FXD0yPSc+5oh/H9Ae2Fo854EfHNk//1otL5W05HTPufvz4N94Nun42qOPvCquqy9Zd8X+OCm9iS7AG8CVgHLWvNuSZZU1U/b9K0jq/rRLNMPmrG5m0bGvwXsP0tJDwOOSHLnSNtS4N1zLLsDsCHJprYHjG5nrue3GaM1kuRRwBuBlQxX9EuBNW32gcANY6xznFr35777Z1ZVdX2SUxleJA5N8ingr6rq5jFqGt3G5vb1PgzPd81IvQGWjCz7vbp3P/oPue8x1wTZB34/k+QUYCfgZuDlI7NOY3gbfkRV7Q48ddOfbMXmDhwZf2jb5kw3Af9RVXuODA+qqj+bY9kfAw8eWXb3qjp00wKbeX5z/ezmzPa3MHRtHNT2wxn8fB/cxNCFNM565qt1A/fdP3Oqqn+rqqcwhHABZ45R08y6Nrevb2N4ET50ZN4eVWVAL2IG+P1Iu7p8LfCHwAuAlyc5rM3ejeEf8J1J9mJ4W721XtY+HD0QeCnwgVmWuRB4VJIXJNmhDb+a5JCZC1bVBuDTwBuS7J7kAUkemeQ3xnh+twJ7J9ljnpp3A+4C7k7yaGD0heRC4JeSnNo+8NstyREj61+x6YPa+WpleHfwkiTLkywDTp+roCQHJzk6yU7A/zIcp03vit4O/H2SgzJ4bJK951jVnPu6qn4GvA14U5J923YPSPKsefaXpsgA3z59PPf+HvhHM9wg8h7gzKq6uqrWMVxdvrsFw1kMH3TdBnwJ+OQC1HE+Q/fDVcC/A+fMXKCqvs/Q/3s8w1XzLQxXlzvNsc4/AnZk+BD1DuA8YL/5nl9VfQ14H/CN9g2T2bpzAP4a+H3g+wyB9v8vOq3WZzD099/C8M2Op7XZH2qP30ty5eZqbfPeBnwKuBq4EvjIHPXQ9sXrGI7NLQzdQ2e0eW9keDH4NMMLzzkMx/E+xtjXr2D4oPpL7Vs5n2F4V6ZFKlX+hw5aeEmKoRvi+mnXIm2vvAKXpE4Z4JLUKbtQJKlTW3UFnmRVux33+iRzfoouSVp4W3wF3n7T4esMn8qvBy5nuPPtqwtXniRpLltzJ+bhwPVV9Q2AJO8HjmX4ytSs2jcTJEm/mNuqap+ZjVvThXIA975Nd31rkyQtrFl/amFrrsBnu8X6PlfYSU4GTt6K7UiSZrE1Ab6ee/+Ww3Jm+a2LqjobOBvsQpGkhbQ1XSiXAwcleXiGH7w/nuG3hCVJE7DFV+BVdU+Sv2D4PYclwDuq6toFq0yStFkTvZHHLhRJ2iJrqmrlzEZvpZekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1Kn5g3wJO9IsjHJNSNteyW5KMm69rhs25YpSZppnCvwdwGrZrSdDqyuqoOA1W1akjRB8wZ4VX0OuH1G87HAuW38XOC4Ba5LkjSPLe0Df0hVbQBoj/suXEmSpHEs3dYbSHIycPK23o4k3d9s6RX4rUn2A2iPG+dasKrOrqqVVbVyC7clSZrFlgb4BcCJbfxE4PyFKUeSNK5xvkb4PuCLwMFJ1id5EfA64BlJ1gHPaNOSpAlKVU1uY8nkNiZJ2481s3VDeyemJHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOjVvgCc5MMnFSdYmuTbJS1v7XkkuSrKuPS7b9uVKkjYZ5wr8HuC0qjoEOBI4JcljgNOB1VV1ELC6TUuSJmTeAK+qDVV1ZRv/PrAWOAA4Fji3LXYucNy2KlKSdF+/UB94khXA44FLgYdU1QYYQh7Yd6GLkyTNbem4CyZ5EPBh4NSquivJuH93MnDylpUnSZrLWFfgSXZgCO/3VtVHWvOtSfZr8/cDNs72t1V1dlWtrKqVC1GwJGkwzrdQApwDrK2qN47MugA4sY2fCJy/8OVJkuaSqtr8AslTgM8DXwF+1prPYOgH/yDwUODbwO9W1e3zrGvzG5MkzWbNbL0Y8wb4QjLAJWmLzBrg3okpSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktSpeQM8yQOTXJbk6iTXJnlNa394kkuTrEvygSQ7bvtyJUmbjHMF/mPg6Kp6HHAYsCrJkcCZwJuq6iDgDuBF265MSdJM8wZ4De5ukzu0oYCjgfNa+7nAcdukQknSrMbqA0+yJMlVwEbgIuAG4M6quqctsh44YI6/PTnJFUmuWIiCJUmDsQK8qn5aVYcBy4HDgUNmW2yOvz27qlZW1cotL1OSNNMv9C2UqroTuAQ4EtgzydI2azlw88KWJknanHG+hbJPkj3b+M7AMcBa4GLgeW2xE4Hzt1WRkqT7Wjr/IuwHnJtkCUPgf7CqLkzyVeD9SV4LfBk4ZxvWKUmaIVWzdl1vm40lk9uYJG0/1sz2OaJ3YkpSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROGeCS1CkDXJI6ZYBLUqcMcEnqlAEuSZ0ywCWpUwa4JHXKAJekThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR1ygCXpE4Z4JLUKQNckjplgEtSpwxwSeqUAS5JnTLAJalTBrgkdcoAl6ROLZ3w9m4DvgU8uI0vJtY0Hmsa32Ksy5rGs9hqethsjamqSRdCkiuqauXEN7wZ1jQeaxrfYqzLmsazGGuajV0oktQpA1ySOjWtAD97StvdHGsajzWNbzHWZU3jWYw13cdU+sAlSVvPLhRJ6tREAzzJqiTXJbk+yemT3PaMOt6RZGOSa0ba9kpyUZJ17XHZhGs6MMnFSdYmuTbJS6ddV5IHJrksydWtpte09ocnubTV9IEkO06qppHaliT5cpILF0NNSW5M8pUkVyW5orVN+5zaM8l5Sb7WzqsnLYKaDm77aNNwV5JTF0Fdf9nO8WuSvK+d+1M/z+czsQBPsgT4Z+A3gccAJyR5zKS2P8O7gFUz2k4HVlfVQcDqNj1J9wCnVdUhwJHAKW3/TLOuHwNHV9XjgMOAVUmOBM4E3tRqugN40QRr2uSlwNqR6cVQ09Oq6rCRr59N+5z6J+CTVfVo4HEM+2uqNVXVdW0fHQY8Efgh8NFp1pXkAOAlwMqq+hVgCXA8i+Oc2ryqmsgAPAn41Mj0K4FXTmr7s9SzArhmZPo6YL82vh9w3bRqazWcDzxjsdQF7AJcCRzBcIPD0tmO64RqWc7wj/xo4EIgi6CmG4EHz2ib2rEDdge+SfucazHUNEuNzwT+c9p1AQcANwF7MdzceCHwrGmfU+MMk+xC2bSTNlnf2haLh1TVBoD2uO+0CkmyAng8cOm062pdFVcBG4GLgBuAO6vqnrbINI7jWcDLgZ+16b0XQU0FfDrJmiQnt7ZpHrtHAN8F3tm6mt6eZNcp1zTT8cD72vjU6qqq7wCvB74NbAD+B1jD9M+peU0ywDNLm1+BmSHJg4APA6dW1V3TrqeqflrD293lwOHAIbMtNql6kvw2sLGq1ow2z7LopM+tJ1fVExi6CE9J8tQJb3+mpcATgLdU1eOBHzD5Lpw5tf7k5wIfWgS1LAOOBR4O7A/synAcZ1p0eTXJAF8PHDgyvRy4eYLbn8+tSfYDaI8bJ11Akh0Ywvu9VfWRxVIXQFXdCVzC0D+/Z5JNv6Mz6eP4ZOC5SW4E3s/QjXLWlGuiqm5ujxsZ+nQPZ7rHbj2wvqoubdPnMQT6ojifGALyyqq6tU1Ps65jgG9W1Xer6ifAR4BfY8rn1DgmGeCXAwe1T3Z3ZHj7dMEEtz+fC4AT2/iJDH3QE5MkwDnA2qp642KoK8k+SfZs4zsznOhrgYuB502jpqp6ZVUtr6oVDOfQZ6vqD6ZZU5Jdk+y2aZyhb/capnjsquoW4KYkB7empwNfnWZNM5zAz7tPYLp1fRs4Msku7d/hpn01tXNqbBP+0OLZwNcZ+lFfNa2Of4YTZwPwE4YrlRcx9KOuBta1x70mXNNTGN6i/TdwVRuePc26gMcCX241XQP8TWt/BHAZcD3DW+CdpnQcjwIunHZNbdtXt+HaTef2IjinDgOuaMfvY8CyadfU6toF+B6wx0jbtPfVa4CvtfP83cBOi+U839zgnZiS1CnvxJSkThngktQpA1ySOmWAS1KnDHBJ6pQBLkmdMsAlqVMGuCR16v8AuOgl/mr1MYMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.imshow(state.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "action = select_action(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADECAYAAACGNXroAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAARO0lEQVR4nO3dfbBU9X3H8fcHLiggyoNiQYgYS3yciIYi1jQ1PiTUNtGZpo22tZixpWntKK2NUTPTapuZ6iRRO5OODQkmVK1PxEc6iRKCTW0TH1CMKCr4TEQQlKJiFOTbP87vxnOX3bsL3Ltnf9zPa+bMnqc957vnnPvZ3/724SoiMDOz/AyqugAzM9s5DnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wK3tJJ0t6f6q6+gkkiZLCkldVddi+XCA72YkvSDpHUlvlYZvVl1X1SSdIGl1P27/UknX99f2zerxs/3u6TMR8aOqi8iNpK6I2Fp1Hf1hd35sA5lb4AOIpGskLShNXyFpsQqjJS2U9JqkN9L4xNK690n6qqT/Ta36uyWNlXSDpE2SHpI0ubR+SDpP0nOS1kv6mqS615ukQyUtkvS6pKcl/WEvj2EfSfMkrZH0i1TT4CaPbwTwA2BC6VXJhNRqXiDpekmbgLMlTZf0U0kb0z6+KWloaZtHlGpdK+kSSTOBS4DPp20/1kKtgyV9PR2b54DfbXLuvpy28WY6RieVtnOJpGfTsqWSJpXOwbmSVgIrmx1rSXukml5Kj+3fJA1Ly06QtFrSBZLWpcf0hd5qtjaICA+70QC8AJzcYNlw4BngbOC3gPXAxLRsLPD7aZ2RwK3AHaX73gesAg4G9gGeTNs6meKV3L8D3y2tH8ASYAzwobTun6VlZwP3p/ERwMvAF9J2jkl1HdHgMdwBfCvdbxzwIPAXLTy+E4DVNdu6FNgCnE7RmBkGfAyYkWqZDKwA5qT1RwJrgAuAPdP0saVtXb8DtX4ReAqYlI7RknTMuuo85kPSMZqQpicDB6fxLwGPp3UEHAWMLZ2DRWn7w5oda+Bq4K60/kjgbuCfS8dvK/CPwBDgVGAzMLrqa34gD5UX4KGPT2gR4G8BG0vDn5eWTwdeB14EzuxlO1OBN0rT9wFfKU1/A/hBafozwLLSdAAzS9N/BSxO42fzQYB/Hvjvmn1/C/iHOjXtD7wLDCvNOxNY0uzx0TjAf9LkeM4Bbi/t69EG611KKcCb1Qr8GPhiadmnaBzgvw6so3iyHFKz7GngtAY1BXBiabrhsaYI/7dJTwxp2XHA86Xj9065vlTTjKqv+YE8uA9893R6NOgDj4gH00v2ccAt3fMlDQeuAmYCo9PskZIGR8T7aXptaVPv1Jneq2Z3L5fGXwQm1CnpQOBYSRtL87qA6xqsOwRYI6l73qDyfho9vl6Ua0TSR4ArgWkULfouYGlaPAl4toVttlLrBLY/PnVFxCpJcyieJI6QdA/wtxHxSgs1lffR27Hej+LxLi3VK2Bwad0N0bMffTPbn3NrI/eBDzCSzgX2AF4BLiwtuoDiZfixEbE38Inuu+zC7iaVxj+U9lnrZeC/ImJUadgrIv6ywbrvAvuW1t07Io7oXqGXx9foZzdr519D0bUxJR2HS/jgGLxM0YXUynaa1bqG7Y9PQxHxHxHxcYoQDuCKFmqqrau3Y72e4kn4iNKyfSLCAd3BHOADSGpdfhX4E+As4EJJU9PikRR/wBsljaF4Wb2rvpTeHJ0EnA/cXGedhcBHJJ0laUgafkPSYbUrRsQa4F7gG5L2ljRI0sGSfruFx7cWGCtpnyY1jwQ2AW9JOhQoP5EsBH5N0pz0ht9ISceWtj+5+43aZrVSvDo4T9JESaOBixoVJOkQSSdK2gP4JcV56n5V9B3gnyRNUeGjksY22FTDYx0R24BvA1dJGpf2e4CkTzc5XlYhB/ju6W71/Bz47Sq+IHI9cEVEPBYRKylal9elYLia4o2u9cDPgB/2QR13UnQ/LAP+E5hXu0JEvEnR/3sGRav5VYrW5R4NtvmnwFCKN1HfABYA45s9voh4CrgReC59wqRedw7A3wF/BLxJEWi/etJJtZ5C0d//KsUnOz6ZFt+abjdIeqS3WtOybwP3AI8BjwC3NaiHdCwupzg3r1J0D12Sll1J8WRwL8UTzzyK87idFo71lyneqP5Z+lTOjyhelVmHUoT/oYP1PUlB0Q2xqupazHZXboGbmWXKAW5mlil3oZiZZWqXWuCSZqav466S1PBddDMz63s73QJPv+nwDMW78quBhyi++fZk35VnZmaN7Mo3MacDqyLiOQBJNwGnUXxkqq70yQQzM9sx6yNiv9qZu9KFcgA9v6a7Os0zM7O+VfenFnalBV7vK9bbtbAlzQZm78J+zMysjl0J8NX0/C2HidT5rYuImAvMBXehmJn1pV3pQnkImCLpIBU/eH8GxW8Jm5lZG+x0Czwitkr6a4rfcxgMXBsRT/RZZWZm1qu2fpHHXShmZjtlaURMq53pf+hgVk/tv++MbdXUYdYL/xaKmVmmHOBmZplygJuZZcp94GZ1DB93YI/pzWufr6gSs8bcAjczy5QD3MwsUw5wM7NMuQ/cDFDX0J7TgwZXVIlZ69wCNzPLlAPczCxTDnAzs0y5D9wMoPZH3dr4I29mO8stcDOzTDnAzcwy5QA3M8uUA9zMLFMOcDOzTDnAzcwy5QA3M8uUA9zMLFMOcDOzTDnAzcwy5QA3M8uUA9zMLFMOcDOzTDnAzcwy5QA3M8tU0wCXdK2kdZKWl+aNkbRI0sp0O7p/yzQzs1qttMC/B8ysmXcRsDgipgCL07SZmbVR0wCPiJ8Ar9fMPg2Yn8bnA6f3cV1mZtbEzvaB7x8RawDS7bi+K8nMzFrR7/8TU9JsYHZ/78fMbKDZ2Rb4WknjAdLtukYrRsTciJgWEdN2cl9mZlbHzgb4XcCsND4LuLNvyjEzs1a18jHCG4GfAodIWi3pHOBy4BRJK4FT0rSZmbVR0z7wiDizwaKT+rgWMzPbAf4mpplZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlikHuJlZphzgZmaZcoCbmWXKAW5mlqmmAS5pkqQlklZIekLS+Wn+GEmLJK1Mt6P7v1wzM+vWSgt8K3BBRBwGzADOlXQ4cBGwOCKmAIvTtJmZtUnTAI+INRHxSBp/E1gBHACcBsxPq80HTu+vIs3MbHs71AcuaTJwNPAAsH9ErIEi5IFxfV2cmZk11tXqipL2Ar4PzImITZJavd9sYPbOlWdmZo201AKXNIQivG+IiNvS7LWSxqfl44F19e4bEXMjYlpETOuLgs3MrNDKp1AEzANWRMSVpUV3AbPS+Czgzr4vz8zMGmmlC+V44CzgcUnL0rxLgMuBWySdA7wE/EH/lGhmZvU0DfCIuB9o1OF9Ut+WY2ZmrfI3Mc3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMtU0wCXtKelBSY9JekLSZWn+QZIekLRS0s2ShvZ/uWZm1q2VFvi7wIkRcRQwFZgpaQZwBXBVREwB3gDO6b8yzcysVtMAj8JbaXJIGgI4EViQ5s8HTu+XCs3aQj0GaVCPwawTtXRlShosaRmwDlgEPAtsjIitaZXVwAEN7jtb0sOSHu6Lgs3MrNBSgEfE+xExFZgITAcOq7dag/vOjYhpETFt58s0M7NaXTuyckRslHQfMAMYJakrtcInAq/0Q31mfWb8PkN6TG9654Pxt997r8eyt9as7LP9HnnkkT2mly9f3mfbtoGtlU+h7CdpVBofBpwMrACWAJ9Lq80C7uyvIs3MbHuttMDHA/MlDaYI/FsiYqGkJ4GbJH0VeBSY1491mplZjaYBHhE/B46uM/85iv5wMzOrwA71gZvlrGtEzw9KxbZffjDx3qv9tt+xY8f227ZtYPMHXM3MMuUANzPLlAPczCxT7gO3AWNb1Fzusa09+93Wnv3YwOMWuJlZphzgZmaZcoCbmWXKfeA2YGx+u+fP9Wze3J79vlfzOytmfcUtcDOzTDnAzcwy5S4UGzDe2NSmPpMaW7ZsqWS/tvtzC9zMLFMOcDOzTDnAzcwy5T5ws342YsSIqkuw3ZRb4GZmmXKAm5llygFuZpYp94Gb9bNBg9xOsv7hK8vMLFMOcDOzTDnAzcwy5T5ws362YcOGqkuw3ZRb4GZmmXKAm5llShHRvp1J7duZmdnuY2lETKud6Ra4mVmmHOBmZplygJuZZardHyNcD7wI7JvGO4lrao1ral0n1uWaWtNpNR1Yb2Zb38T81U6lh+t1yFfJNbXGNbWuE+tyTa3pxJrqcReKmVmmHOBmZpmqKsDnVrTf3rim1rim1nViXa6pNZ1Y03Yq6QM3M7Nd5y4UM7NMtTXAJc2U9LSkVZIuaue+a+q4VtI6SctL88ZIWiRpZbod3eaaJklaImmFpCcknV91XZL2lPSgpMdSTZel+QdJeiDVdLOkoe2qqVTbYEmPSlrYCTVJekHS45KWSXo4zav6mholaYGkp9J1dVwH1HRIOkbdwyZJczqgrr9J1/hySTema7/y67yZtgW4pMHAvwK/AxwOnCnp8Hbtv8b3gJk18y4CFkfEFGBxmm6nrcAFEXEYMAM4Nx2fKut6FzgxIo4CpgIzJc0ArgCuSjW9AZzTxpq6nQ+sKE13Qk2fjIippY+fVX1N/Qvww4g4FDiK4nhVWlNEPJ2O0VTgY8Bm4PYq65J0AHAeMC0ijgQGA2fQGddU7yKiLQNwHHBPafpi4OJ27b9OPZOB5aXpp4HxaXw88HRVtaUa7gRO6ZS6gOHAI8CxFF9w6Kp3XttUy0SKP/ITgYWAOqCmF4B9a+ZVdu6AvYHnSe9zdUJNdWr8FPA/VdcFHAC8DIyh+HLjQuDTVV9TrQzt7ELpPkjdVqd5nWL/iFgDkG7HVVWIpMnA0cADVdeVuiqWAeuARcCzwMaI2JpWqeI8Xg1cCGxL02M7oKYA7pW0VNLsNK/Kc/dh4DXgu6mr6TuSRlRcU60zgBvTeGV1RcQvgK8DLwFrgP8DllL9NdVUOwNcdeb5IzA1JO0FfB+YExGbqq4nIt6P4uXuRGA6cFi91dpVj6TfA9ZFxNLy7DqrtvvaOj4ijqHoIjxX0ifavP9aXcAxwDURcTTwNu3vwmko9Sd/Fri1A2oZDZwGHARMAEZQnMdaHZdX7Qzw1cCk0vRE4JU27r+ZtZLGA6Tbde0uQNIQivC+ISJu65S6ACJiI3AfRf/8KEndv6PT7vN4PPBZSS8AN1F0o1xdcU1ExCvpdh1Fn+50qj13q4HVEfFAml5AEegdcT1RBOQjEbE2TVdZ18nA8xHxWkRsAW4DfpOKr6lWtDPAHwKmpHd2h1K8fLqrjftv5i5gVhqfRdEH3TaSBMwDVkTElZ1Ql6T9JI1K48MoLvQVwBLgc1XUFBEXR8TEiJhMcQ39OCL+uMqaJI2QNLJ7nKJvdzkVnruIeBV4WdIhadZJwJNV1lTjTD7oPoFq63oJmCFpePo77D5WlV1TLWvzmxanAs9Q9KN+paqOf4oLZw2whaKlcg5FP+piYGW6HdPmmj5O8RLt58CyNJxaZV3AR4FHU03Lgb9P8z8MPAisongJvEdF5/EEYGHVNaV9P5aGJ7qv7Q64pqYCD6fzdwcwuuqaUl3DgQ3APqV5VR+ry4Cn0nV+HbBHp1znvQ3+JqaZWab8TUwzs0w5wM3MMuUANzPLlAPczCxTDnAzs0w5wM3MMuUANzPLlAPczCxT/w/3BU3CRiPAzQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NS, reward, done, _ = env.step(action.item())\n",
    "last_screen = current_screen\n",
    "current_screen = get_screen()\n",
    "next_state = current_screen - last_screen\n",
    "plt.figure()\n",
    "plt.imshow(next_state.cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.push(state, action, next_state, reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 40, 90])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0]], device='cuda:0')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.position = 0\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Saves a transition.\"\"\"\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(None)\n",
    "        self.memory[self.position] = Transition(*args)\n",
    "        self.position = (self.position + 1) % self.capacity\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
